# Warmth Engine Observatory - Methodology Changelog

## [1.0.0] - October 2025

### Framework Components

**Analytical Prophecy Methodology Framework (APMF):** Published September 2025
- Four-Headed Analysis (Technological, Financial, Psychological, Governance)
- Post-Convergence Strategic Analysis (added October 2025)
- Coordination-emergence uncertainty management
- Pattern recognition over causal certainty

**C-MAD Framework:** Computational Mutual Assured Destruction
- Game-theoretic analysis (Stag Hunt vs Prisoner's Dilemma)
- Operational-phase coordination pressure assessment
- Infrastructure concentration and mutual vulnerability

**WE Global Stability Index (WE GSI):** Version 1.0
- Five-dimensional scoring framework
- Bipolar assessment (-2 to +2 per dimension)
- Four Heads + Temporal Momentum structure
- Quantitative operationalization of APMF

### Dimensional Framework

**Dimension 1: Technological Head Coordination** (-2 to +2)
- Infrastructure integration vs sovereignty
- System interoperability vs proprietary isolation
- Supply chain openness vs chokepoint control
- Energy infrastructure coordination for AI compute

**Dimension 2: Financial Head Coordination** (-2 to +2)
- Capital flow openness vs restrictions
- Investment patterns (joint vs competitive)
- Government funding and subsidies
- FDI screening and outbound investment controls

**Dimension 3: Psychological Head Coordination** (-2 to +2)
- Trust formation vs adversarial positioning
- Behavioral conditioning and narrative framing
- Shared ethical frameworks vs competing values
- Assurance mechanisms reducing coordination risk

**Dimension 4: Governance Head Coordination** (-2 to +2)
- Policy alignment vs fragmentation
- Regulatory coordination vs adversarial frameworks
- Technical standards adoption vs proprietary ecosystems
- Data governance frameworks (cross-border flows vs localization)

**Dimension 5: Temporal Momentum** (-1 to +1)
- Recent directional change across all dimensions
- 90-day assessment window
- Captures acceleration or deceleration of trends

### Scoring Methodology

**Individual Signal Assessment:**
- Each signal scored across all 5 dimensions
- Signal Score = sum of dimensional scores
- Range: -10 (maximum fragmentation) to +10 (maximum coordination)

**Signal Type Weighting:**
- **Weight 4:** Coordination mechanism signals (bilateral agreements, joint frameworks)
- **Weight 3:** Infrastructure commitment signals (major investments >$1B, facility builds)
- **Weight 2:** Policy framework signals (legislation, regulatory changes)
- **Weight 1:** Corporate partnership signals (standard commercial agreements)

**WE GSI Calculation:**
```
Raw Score = Σ (Signal Score × Signal Type Weight)
GSI % = 50 + (Raw Score / Maximum Possible Raw Score) × 50
```

**Stability Categories:**
- **0-33%:** LOW/RED (Dangerous Fragmentation) - Prisoner's Dilemma dynamics dominating
- **34-66%:** MEDIUM/AMBER (Transitional Uncertainty) - Equilibrium unresolved between coordination and fragmentation
- **67-100%:** HIGH/GREEN (Stable Coordination) - Stag Hunt payoff-dominant equilibrium achieved

### Observable Outcomes Prioritization

**Tier 1 (100% weight):** Observable outcomes
- Actual infrastructure built, trade flows changed, facilities operating
- Enacted legislation in force
- Closed funding rounds with verified capital deployment

**Tier 2 (75% weight):** Verifiable commitments
- Signed treaties with deliverables, announced investments with timelines
- Regulatory proposals with legislative text
- Partnership MOUs with defined scope

**Tier 3 (50% weight):** Stated intent
- Non-binding agreements, policy statements without mechanisms
- Aspirational government strategies
- Industry voluntary commitments

**Tier 4 (0% weight):** Unverifiable claims
- Private negotiations, rumors, speculative motivations
- Hypothetical future actions without commitments

### Epistemic Boundaries

**Core Acknowledgment:**
The WE GSI provides quantitative structure to pattern assessment, not precision measurement. Given systematic opacity in AI infrastructure, we score observable public signals rather than attempting to measure unknowable operational realities.

**What We Can Score:**
- Announced policies and enacted regulations
- Verifiable infrastructure commitments
- Observable facility builds and capital deployments
- Public investment data and trade flows

**What Remains Unknowable:**
- Classified military AI programs (estimated 20-40% of advanced compute)
- Actual subsidy amounts in non-transparent economies
- Informal coordination mechanisms (back-channel communications)
- True effectiveness of announced policies vs. stated goals
- Proprietary AI development specifications

**Methodological Principle:**
"We document patterns rather than prove coordination. Complex systems often require analysis before definitive proof becomes available."

### APMF Alignment

**Pattern Recognition Over Causal Certainty:**
- Score observable patterns, not claimed intentions
- Use "consistent with" language, not "proves"
- Acknowledge coordination-emergence uncertainty
- Consider alternative explanations (market forces, regulatory learning, coincidence)

**Multi-Domain Convergence:**
- Assess signals across all four APMF heads simultaneously
- Avoid double-counting (score primary effect fully, reduce secondary effects)
- Maintain dimensional independence

**Coordination-Emergence Uncertainty:**
- Observable coordination may emerge from deliberate strategy OR convergent evolution
- Framework acknowledges this uncertainty explicitly
- Does not claim definitive proof of coordination intent

**Epistemic Humility:**
- Explicit limitations statement in all WE GSI reports
- Confidence intervals provided when possible
- Known systematic biases documented (Western source bias, recency bias, observability bias)

### Game-Theoretic Foundations

**C-MAD vs MAIM Distinction:**

**MAIM (Mutual Assured AI Malfunction):**
- Addresses pre-deployment phase through deterrence
- Prevents dangerous AI development via credible sabotage threats
- Targets adversaries' computational infrastructure

**C-MAD (Computational Mutual Assured Destruction):**
- Addresses operational phase through coordination
- Manages existing dependencies once AI systems integrated into critical infrastructure
- Disruption harms all parties simultaneously → Stag Hunt dynamics

**WE GSI Game-Theoretic Interpretation:**
- **HIGH/GREEN:** Patterns consistent with Stag Hunt payoff-dominant equilibrium achieved
- **MEDIUM/AMBER:** Equilibrium unresolved between Stag Hunt cooperation and Prisoner's Dilemma defection
- **LOW/RED:** Prisoner's Dilemma dynamics dominating despite mutual vulnerability

### Observable Signal Types

**Technological Head:**
- Data center construction (satellite imagery, building permits, press releases)
- Cloud platform regional availability
- Export control entity lists
- Power purchase agreements for AI infrastructure
- Supply chain trade data (6-12 month lag)

**Financial Head:**
- Investment screening decisions (CFIUS, EU FDI reports)
- Government funding announcements and allocations
- Sovereign wealth fund investments
- Outbound investment control regulations
- Venture capital databases (aggregate trends)

**Psychological Head:**
- International agreement texts (ethical principles, codes of conduct)
- Public sentiment surveys on AI
- Official government rhetoric in national security strategies
- Partnership announcements and dissolutions
- Academic/industry collaboration patterns

**Governance Head:**
- Legislative and regulatory texts
- Treaty ratifications and international agreements
- Standards body voting records (ISO/IEC)
- Export control entity list updates
- Mutual recognition agreement status
- Compliance guidance documents

### Known Limitations

**Systematic Biases:**

**Bias Toward Observable Fragmentation:**
- Fragmentation signals (export controls, investment bans) often public and explicit
- Coordination signals (informal cooperation, gradual trust-building) less observable
- Mitigation: Actively seek positive coordination signals beyond government press releases

**Bias Toward Western Sources:**
- English-language sources dominate (Federal Register, EU Official Journal)
- Chinese/Russian policy documents less accessible or require translation
- Mitigation: Include translated official sources (MIIT, NDRC); partner with multilingual researchers

**Recency Bias:**
- Temporal Momentum privileges recent signals
- Long-term structural coordination (Five Eyes, EU integration) may be under-weighted
- Mitigation: Track "legacy coordination infrastructure" separately from new signals

**Publication Lag:**
- Trade data has 6-12 month lag
- Investment data quarterly/annual
- Real-time policy moves (executive orders) immediately scorable
- Mitigation: Note data vintage; update retroactively when lagged data published

### Future Evolution

This methodology will evolve as:
- More signals are assessed (pattern refinement)
- Framework is tested against real-world developments
- Research community provides feedback
- Coordination dynamics shift
- Technology evolution renders current measures obsolete

**Version Update Triggers:**

**Minor Updates (1.1, 1.2, etc.):**
- Clarifications to scoring criteria
- Addition of new signal type examples
- Bug fixes in calculation formula
- Do not break time series comparability

**Major Updates (2.0, 3.0, etc.):**
- Dimensional framework changes (adding/removing dimensions)
- Fundamental recalculation of weights
- Paradigm shifts in measurement approach
- Require recalculation of all historical signals OR time series break

All version updates will be documented in this changelog with rationale for changes and impact assessment on historical comparability.

---

## Methodology Version History

### [1.0.0] - October 2025
- Initial framework establishment
- APMF Four-Headed structure operationalized
- Bipolar dimensional scoring implemented (-2 to +2 per dimension)
- Post-Convergence Strategic Analysis integrated
- Five-dimensional framework: Tech, Financial, Psychological, Governance, Temporal
- Signal type weighting system established (1-4×)
- WE GSI calculation formula defined
- Epistemic boundaries explicitly documented
- Game-theoretic foundations (C-MAD) integrated with scoring interpretation
- Observable outcomes prioritization hierarchy established (Tiers 1-4)

**Core Innovation:** Quantitative operationalization of APMF Four-Headed Analysis for systematic AI infrastructure coordination assessment while maintaining methodological rigor through explicit epistemic boundaries and pattern recognition over causal certainty.

---

## Contact & Feedback

For methodology questions, suggested refinements, or external validation inquiries:
- Email: warmthengine@proton.me
- Framework evolves through community feedback and empirical testing

**Transparency Commitment:** All methodology changes documented here with clear rationale, ensuring longitudinal dataset integrity and replicability.

---

**Document Version:** 1.0  
**Last Updated:** October 2025  
**Next Scheduled Review:** January 2026 (Quarterly)
